# be/api.py
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import pandas as pd
import numpy as np

from be.data_utils import get_country_list_worldbank, get_series_for_country
from be.gpt_utils import gemini_analyze_summary

app = FastAPI(title="Population API")

# (t√πy ch·ªçn nh∆∞ng n√™n c√≥) ƒë·ªÉ FE g·ªçi backend kh√¥ng b·ªã CORS khi deploy/t√°ch domain
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ---------- Models ----------
class AnalyzeReq(BaseModel):
    summary_text: str


class ReviseReq(BaseModel):
    # h·ªó tr·ª£ nhi·ªÅu format ƒë·ªÉ t∆∞∆°ng th√≠ch FE/backwards
    report_markdown: str | None = None
    report_text: str | None = None
    markdown: str | None = None
    report: str | None = None

    edit_request: str | None = None
    request: str | None = None

    system_prompt: str | None = None


DEFAULT_REVISE_PROMPT = """
B·∫°n s·∫Ω ch·ªânh s·ª≠a b√°o c√°o markdown hi·ªán c√≥ theo y√™u c·∫ßu ng∆∞·ªùi d√πng.
Y√™u c·∫ßu:
- Gi·ªØ markdown g·ªçn g√†ng, nh·∫•t qu√°n.
- Kh√¥ng l·∫∑p l·∫°i to√†n b·ªô n·ªôi dung kh√¥ng c·∫ßn thi·∫øt.
- Ch·ªâ tr·∫£ v·ªÅ phi√™n b·∫£n b√°o c√°o markdown cu·ªëi c√πng (kh√¥ng th√™m gi·∫£i th√≠ch, kh√¥ng th√™m l·ªùi d·∫´n).
""".strip()


# ---------- Utils ----------
def df_to_records_safe(df: pd.DataFrame):
    if df is None or df.empty:
        return []
    clean = df.copy()
    clean.replace([np.inf, -np.inf], np.nan, inplace=True)
    clean = clean.astype(object).where(pd.notna(clean), None)
    return clean.to_dict(orient="records")


def _pick_first_non_empty(*vals: str | None) -> str:
    for v in vals:
        if v is None:
            continue
        s = str(v).strip()
        if s:
            return s
    return ""


# ---------- Routes ----------
@app.get("/health")
def health():
    return {"status": "ok"}


@app.get("/worldbank/countries")
def countries():
    return get_country_list_worldbank()


@app.get("/worldbank/series/{country_id}")
def series(country_id: str, start_year: int, end_year: int):
    try:
        df = get_series_for_country(country_id, start_year, end_year)
        return df_to_records_safe(df)
    except HTTPException:
        raise
    except Exception as e:
        # tr·∫£ l·ªói r√µ r√†ng, kh√¥ng ‚Äú500 m√π‚Äù
        raise HTTPException(status_code=400, detail=f"Cannot load series for '{country_id}': {e}")


@app.post("/ai/analyze")
def analyze(req: AnalyzeReq):
    if not (req.summary_text or "").strip():
        raise HTTPException(status_code=400, detail="summary_text is empty")
    try:
        md = gemini_analyze_summary(req.summary_text)
        if not (md or "").strip():
            raise HTTPException(status_code=502, detail="Gemini returned empty response")
        return {"markdown": md}
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


# nh·∫≠n c·∫£ 2 path ƒë·ªÉ tr√°nh l·ªói / v√† kh√¥ng /
@app.post("/ai/revise")
@app.post("/ai/revise/")
def revise(req: ReviseReq):
    report_md = _pick_first_non_empty(req.report_markdown, req.report_text, req.markdown, req.report)
    edit_req = _pick_first_non_empty(req.edit_request, req.request)
    system_prompt = (req.system_prompt or DEFAULT_REVISE_PROMPT).strip()

    if not report_md:
        raise HTTPException(status_code=400, detail="report markdown is empty")
    if not edit_req:
        raise HTTPException(status_code=400, detail="edit_request is empty")

    # D√πng chung h√†m gemini_analyze_summary: coi nh∆∞ ‚Äú1 prompt l·ªõn‚Äù
    prompt = "\n".join(
        [
            "### SYSTEM PROMPT",
            system_prompt,
            "",
            "### B√ÅO C√ÅO HI·ªÜN T·∫†I (MARKDOWN)",
            report_md,
            "",
            "### Y√äU C·∫¶U CH·ªàNH S·ª¨A",
            edit_req,
        ]
    ).strip()

    try:
        md = gemini_analyze_summary(prompt)
        if not (md or "").strip():
            raise HTTPException(status_code=502, detail="Gemini returned empty response")
        return {"markdown": md}
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


# ========== NEW ENDPOINTS - LOGIC TH·ª¶ C√îNG ==========

from datetime import datetime
from be.statistical_processor import StatisticalProcessor
from be.validators import DataQualityValidator
from be.ai_hallucination_detector import AIHallucinationDetector


@app.post("/statistics/process")
def process_statistics(country_id: str, start_year: int, end_year: int, country_name: str):
    """
    X·ª¨ L√ù TH·ªêNG K√ä B·∫∞NG CODE TH·ª¶ C√îNG - Endpoint quan tr·ªçng nh·∫•t
    Thay th·∫ø AI trong vi·ªác t√≠nh to√°n
    """
    try:
        # Load data t·ª´ World Bank
        df = get_series_for_country(country_id, start_year, end_year)
        
        # Validate data quality TR∆Ø·ªöC khi x·ª≠ l√Ω
        validator = DataQualityValidator()
        quality_check = validator.validate_data_ranges(df)
        completeness = validator.check_data_completeness(df)
        
        # X·ª¨ L√ù TH·ªêNG K√ä TH·ª¶ C√îNG
        processor = StatisticalProcessor()
        statistics = processor.process_country_statistics(df, country_name)
        
        # Generate summary table
        summary_table = processor.generate_summary_table(statistics)
        
        return {
            "statistics": statistics,
            "summary_table": summary_table.to_dict(orient='records'),
            "data_quality": {
                **quality_check,
                **completeness
            },
            "processing_method": "manual_code",  # KH√îNG ph·∫£i AI
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/statistics/compare")
def compare_countries_stats(req: dict):
    """
    So s√°nh 2 qu·ªëc gia b·∫±ng code th·ªß c√¥ng
    """
    try:
        country1_stats = req.get("country1_stats", {})
        country2_stats = req.get("country2_stats", {})
        
        if not country1_stats or not country2_stats:
            raise HTTPException(status_code=400, detail="Missing country statistics")
        
        processor = StatisticalProcessor()
        comparison = processor.compare_countries(country1_stats, country2_stats)
        
        return {
            "comparison": comparison,
            "processing_method": "manual_code"
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/ai/analyze-with-stats")
def analyze_with_stats(req: dict):
    """
    AI ph√¢n t√≠ch BASED ON statistics ƒë√£ x·ª≠ l√Ω
    AI KH√îNG ƒë∆∞·ª£c t·ª± t√≠nh - ch·ªâ nh·∫≠n s·ªë li·ªáu c√≥ s·∫µn
    """
    statistics = req.get('statistics', {})
    user_prompt = req.get('user_prompt', '')
    
    if not statistics:
        raise HTTPException(status_code=400, detail="statistics is required")
    
    # Build prompt v·ªõi s·ªë li·ªáu ƒë√£ t√≠nh
    prompt = _build_ai_prompt_from_statistics(statistics, user_prompt)
    
    try:
        md = gemini_analyze_summary(prompt, user_prompt)
        
        return {
            "markdown": md,
            "source_statistics": statistics,  # ƒê·ªÉ validate sau
            "processing_method": "ai_analysis"
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


def _build_ai_prompt_from_statistics(statistics: dict, user_prompt: str = "") -> str:
    """T·∫°o prompt t·ªëi ∆∞u cho AI v·ªõi s·ªë li·ªáu ƒë√£ t√≠nh s·∫µn"""
    
    # Handle multiple countries
    if "countries" in statistics:
        # Multiple countries case
        countries_data = statistics["countries"]
        
        # Get time period from first country
        first_country_stats = list(countries_data.values())[0]
        data_period = first_country_stats['data_period']
        start_year = data_period['start_year']
        end_year = data_period['end_year']
        
        prompt_parts = [
            f"**KHO·∫¢NG TH·ªúI GIAN: {start_year}-{end_year}**",
            "",
            "‚ö†Ô∏è Y√äU C·∫¶U VALIDATION:",
            f"- Ph√¢n t√≠ch TO√ÄN B·ªò giai ƒëo·∫°n {start_year}-{end_year}",
            "- COPY CH√çNH X√ÅC s·ªë li·ªáu d∆∞·ªõi ƒë√¢y (ƒë·∫øn 2 ch·ªØ s·ªë th·∫≠p ph√¢n)",
            "- D√πng ƒê√öNG xu h∆∞·ªõng t·ª´ c·ªôt 'Xu h∆∞·ªõng'",
            "- CH·ªà d√πng M·ªòT t·ª´ (tƒÉng/gi·∫£m/·ªïn ƒë·ªãnh) cho m·ªói ch·ªâ s·ªë",
            "",
            "## D·ªÆ LI·ªÜU ƒê√É X·ª¨ L√ù"
        ]
        
        for country_name, stats in countries_data.items():
            birth = stats["birth_rate_analysis"]
            death = stats["death_rate_analysis"]
            trend = stats["trend_analysis"]
            demo = stats["demographic_indicators"]
            period = stats["data_period"]
            
            # Determine trend direction with explicit Vietnamese term
            birth_trend_vn = "GI·∫¢M" if trend['birth_rate']['direction'] == "decreasing" else (
                "TƒÇNG" if trend['birth_rate']['direction'] == "increasing" else "·ªîN ƒê·ªäNH"
            )
            death_trend_vn = "GI·∫¢M" if trend['death_rate']['direction'] == "decreasing" else (
                "TƒÇNG" if trend['death_rate']['direction'] == "increasing" else "·ªîN ƒê·ªäNH"
            )
            
            prompt_parts.extend([
                f"",
                f"### {country_name} ({period['start_year']}-{period['end_year']})",
                f"",
                f"**üìå T·ªà L·ªÜ SINH (BIRTH RATE):**",
                f"```",
                f"Gi√° tr·ªã trung b√¨nh:     {birth['mean']}‚Ä∞        ‚Üê COPY CH√çNH X√ÅC s·ªë n√†y",
                f"NƒÉm {period['start_year']}:       {birth['first_value']}‚Ä∞",
                f"NƒÉm {period['end_year']}:       {birth['last_value']}‚Ä∞",
                f"Thay ƒë·ªïi:               {birth['total_change']}‚Ä∞ ({birth['percent_change']}%)",
                f"Xu h∆∞·ªõng:               {birth_trend_vn}         ‚Üê CH·ªà d√πng t·ª´ n√†y!",
                f"ƒê·ªô tin c·∫≠y:             R¬≤={trend['birth_rate']['r_squared']}, p={trend['birth_rate']['p_value']}",
                f"```",
                f"",
                f"**üìå T·ªà L·ªÜ T·ª¨ (DEATH RATE):**",
                f"```",
                f"Gi√° tr·ªã trung b√¨nh:     {death['mean']}‚Ä∞        ‚Üê COPY CH√çNH X√ÅC s·ªë n√†y",
                f"Thay ƒë·ªïi:               {death['total_change']}‚Ä∞ ({death['percent_change']}%)",
                f"Xu h∆∞·ªõng:               {death_trend_vn}         ‚Üê CH·ªà d√πng t·ª´ n√†y!",
                f"```",
                f"",
                f"**üìå CH·ªà S·ªê KH√ÅC:**",
                f"```",
                f"TƒÉng t·ª± nhi√™n:          {demo['natural_increase_rate']}‚Ä∞",
                f"Giai ƒëo·∫°n d√¢n s·ªë:       {demo['demographic_stage']}",
                f"```"
            ])
    else:
        # Single country
        country = statistics['country']
        birth = statistics['birth_rate_analysis']
        death = statistics['death_rate_analysis']
        trend = statistics['trend_analysis']
        demo = statistics['demographic_indicators']
        period = statistics['data_period']
        
        # Explicit Vietnamese trend terms
        birth_trend_vn = "GI·∫¢M" if trend['birth_rate']['direction'] == "decreasing" else (
            "TƒÇNG" if trend['birth_rate']['direction'] == "increasing" else "·ªîN ƒê·ªäNH"
        )
        death_trend_vn = "GI·∫¢M" if trend['death_rate']['direction'] == "decreasing" else (
            "TƒÇNG" if trend['death_rate']['direction'] == "increasing" else "·ªîN ƒê·ªäNH"
        )
        
        prompt_parts = [
            f"**KHO·∫¢NG TH·ªúI GIAN: {period['start_year']}-{period['end_year']}**",
            "",
            "‚ö†Ô∏è Y√äU C·∫¶U VALIDATION:",
            f"- Ph√¢n t√≠ch TO√ÄN B·ªò giai ƒëo·∫°n {period['start_year']}-{period['end_year']}",
            "- COPY CH√çNH X√ÅC s·ªë li·ªáu d∆∞·ªõi ƒë√¢y",
            "- D√πng ƒê√öNG xu h∆∞·ªõng t·ª´ c·ªôt 'Xu h∆∞·ªõng'",
            "- KH√îNG t·ª± m√¢u thu·∫´n",
            "",
            f"## D·ªÆ LI·ªÜU - {country} ({period['start_year']}-{period['end_year']})",
            f"",
            f"**üìå T·ªà L·ªÜ SINH (BIRTH RATE):**",
            f"```",
            f"Trung b√¨nh giai ƒëo·∫°n:   {birth['mean']}‚Ä∞        ‚Üê COPY s·ªë n√†y",
            f"NƒÉm {period['start_year']}:       {birth['first_value']}‚Ä∞",
            f"NƒÉm {period['end_year']}:       {birth['last_value']}‚Ä∞",
            f"Thay ƒë·ªïi:               {birth['total_change']}‚Ä∞ ({birth['percent_change']}%)",
            f"**XU H∆Ø·ªöNG: {birth_trend_vn}**   ‚Üê B·∫ÆT BU·ªòC d√πng t·ª´ n√†y!",
            f"R¬≤:                     {trend['birth_rate']['r_squared']}",
            f"```",
            f"",
            f"**üìå T·ªà L·ªÜ T·ª¨ (DEATH RATE):**",
            f"```",
            f"Trung b√¨nh:             {death['mean']}‚Ä∞",
            f"Thay ƒë·ªïi:               {death['total_change']}‚Ä∞",
            f"**XU H∆Ø·ªöNG: {death_trend_vn}**   ‚Üê B·∫ÆT BU·ªòC d√πng t·ª´ n√†y!",
            f"```",
            f"",
            f"**üìå CH·ªà S·ªê KH√ÅC:**",
            f"- TƒÉng t·ª± nhi√™n: {demo['natural_increase_rate']}‚Ä∞",
            f"- Giai ƒëo·∫°n d√¢n s·ªë: {demo['demographic_stage']}"
        ]
    
    if user_prompt:
        prompt_parts.extend([
            "",
            "## Y√äU C·∫¶U B·ªî SUNG C·ª¶A NG∆Ø·ªúI D√ôNG",
            user_prompt
        ])
    
    prompt_parts.extend([
        "",
        "---",
        "üí° REMINDER: Validation s·∫Ω ki·ªÉm tra:",
        "1. S·ªë li·ªáu c√≥ kh·ªõp kh√¥ng (tolerance 5%)",
        "2. Xu h∆∞·ªõng c√≥ ƒë√∫ng kh√¥ng",
        "3. C√≥ t·ª± m√¢u thu·∫´n kh√¥ng",
        "",
        "Vi·∫øt b√°o c√°o MARKDOWN, KH√îNG code block."
    ])
    
    return "\n".join(prompt_parts)


@app.post("/ai/regenerate-with-feedback")
def regenerate_with_feedback(req: dict):
    """
    REGENERATE AI REPORT v·ªõi feedback t·ª´ validation
    Auto-refinement loop cho ƒë·∫øn khi ƒë·∫°t 95/100
    """
    validation_feedback = req.get('validation_feedback', {})
    statistics = req.get('statistics', {})
    user_prompt = req.get('user_prompt', '')
    
    if not statistics:
        raise HTTPException(status_code=400, detail="statistics required")
    
    # Build detailed feedback
    feedback_parts = ["## FEEDBACK T·ª™ H·ªÜ TH·ªêNG VALIDATION\n"]
    score = validation_feedback.get('hallucination_score', 0)
    verdict = validation_feedback.get('verdict', 'UNKNOWN')
    feedback_parts.append(f"**ƒêi·ªÉm hi·ªán t·∫°i:** {score}/100 ({verdict})\n")
    
    # Statistics verification issues
    stats_verif = validation_feedback.get('statistics_verification', {})
    if stats_verif.get('suspicious', []):
        feedback_parts.append("**‚ö†Ô∏è C√°c s·ªë li·ªáu SAI L·ªÜCH c·∫ßn s·ª≠a:**")
        for item in stats_verif['suspicious']:
            feedback_parts.append(
                f"- {item['stat_name']}: AI n√≥i {item['ai_value']}, "
                f"th·ª±c t·∫ø l√† {item['actual_value']} (sai l·ªách {item['error_pct']}%)"
            )
        feedback_parts.append("")
    
    if stats_verif.get('hallucinations', []):
        feedback_parts.append("**‚ùå C√°c s·ªë li·ªáu B·ªäA/THI·∫æU:**")
        for item in stats_verif['hallucinations']:
            if item.get('ai_value') is None:
                feedback_parts.append(f"- {item['stat_name']}: THI·∫æU - C·∫ßn th√™m {item['actual_value']}")
            else:
                feedback_parts.append(
                    f"- {item['stat_name']}: AI b·ªãa {item['ai_value']}, "
                    f"th·ª±c t·∫ø l√† {item['actual_value']}"
                )
        feedback_parts.append("")
    
    # Trend issues
    trend_check = validation_feedback.get('trend_check', {})
    if not trend_check.get('correct', True):
        feedback_parts.append("**‚ùå SAI XU H∆Ø·ªöNG:**")
        feedback_parts.append(f"- {trend_check.get('verdict', '')}")
        feedback_parts.append("")
    
    # Contradictions
    contradictions = validation_feedback.get('contradictions', [])
    if len(contradictions) > 0:
        feedback_parts.append(f"**‚ö†Ô∏è M√ÇU THU·∫™N N·ªòI B·ªò ({len(contradictions)} ch·ªó):**")
        for c in contradictions[:5]:
            feedback_parts.append(f"- {c.get('explanation', 'Unknown')}")
        if len(contradictions) > 5:
            feedback_parts.append(f"- ... v√† {len(contradictions) - 5} m√¢u thu·∫´n kh√°c")
        feedback_parts.append("")
    
    # Recommendations
    recommendations = validation_feedback.get('recommendations', [])
    if recommendations:
        feedback_parts.append("**üìã H∆Ø·ªöNG D·∫™N S·ª¨A:**")
        for rec in recommendations:
            feedback_parts.append(f"- {rec}")
        feedback_parts.append("")
    
    feedback_text = "\n".join(feedback_parts)
    
    # Build regeneration prompt
    base_prompt = _build_ai_prompt_from_statistics(statistics, user_prompt)
    
    regeneration_prompt = f"""{base_prompt}

## Y√äU C·∫¶U REGENERATE

B√°o c√°o tr∆∞·ªõc c√≥ c√°c v·∫•n ƒë·ªÅ sau:

{feedback_text}

**NHI·ªÜM V·ª§:**
1. Vi·∫øt L·∫†I to√†n b·ªô b√°o c√°o
2. S·ª¨A t·∫•t c·∫£ c√°c s·ªë li·ªáu sai l·ªách/b·ªãa/thi·∫øu
3. S·ª¨A xu h∆∞·ªõng n·∫øu sai  
4. LO·∫†I B·ªé m√¢u thu·∫´n n·ªôi b·ªô
5. ƒê·∫¢M B·∫¢O d√πng CH√çNH X√ÅC s·ªë li·ªáu ƒë√£ cho
6. ƒê·∫¢M B·∫¢O n√≥i r√µ kho·∫£ng th·ªùi gian khi ph√¢n t√≠ch

Tr·∫£ v·ªÅ MARKDOWN thu·∫ßn t√∫y, KH√îNG nh·∫Øc l·∫°i v·∫•n ƒë·ªÅ ƒë√£ s·ª≠a.
"""
    
    try:
        md = gemini_analyze_summary(regeneration_prompt, "")
        
        return {
            "markdown": md,
            "source_statistics": statistics,
            "processing_method": "ai_regeneration_with_feedback",
            "iteration_feedback": feedback_text
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/validate/ai-report")
def validate_ai_report(req: dict):
    """
    VALIDATE AI REPORT - Ph√°t hi·ªán AI b·ªãa n·ªôi dung
    ƒê√ÇY L√Ä LOGIC QUAN TR·ªåNG NH·∫§T
    """
    ai_report = req.get('ai_report', '')
    source_statistics = req.get('source_statistics', {})
    
    if not ai_report:
        raise HTTPException(status_code=400, detail="ai_report is required")
    if not source_statistics:
        raise HTTPException(status_code=400, detail="source_statistics is required")
    
    try:
        detector = AIHallucinationDetector()
        
        # Extract actual stats ƒë·ªÉ so s√°nh
        actual_stats = {}
        actual_trend = None
        country_name = None
        
        try:
            # Handle both single and multiple countries
            print(f"[DEBUG] source_statistics keys: {list(source_statistics.keys())}")
            
            if "countries" in source_statistics:
                # Multiple countries - use first one for trend check
                print(f"[DEBUG] Multiple countries mode, countries: {list(source_statistics['countries'].keys())}")
                first_country = list(source_statistics["countries"].keys())[0]
                stats = source_statistics["countries"][first_country]
                country_name = first_country
                print(f"[DEBUG] Selected country: {country_name}")
                print(f"[DEBUG] Stats keys: {list(stats.keys())}")
            else:
                # Single country
                print(f"[DEBUG] Single country mode")
                stats = source_statistics
                country_name = stats.get('country', 'Unknown')
                print(f"[DEBUG] Country name: {country_name}")
                print(f"[DEBUG] Stats keys: {list(stats.keys())}")
            
            print(f"[DEBUG] Extracting actual_stats...")
            actual_stats = {
                "birth_rate_avg": stats['birth_rate_analysis']['mean'],
                "death_rate_avg": stats['death_rate_analysis']['mean'],
                "birth_min": stats['birth_rate_analysis']['min'],
                "birth_max": stats['birth_rate_analysis']['max'],
                "natural_increase": stats['demographic_indicators']['natural_increase_rate']
            }
            print(f"[DEBUG] Actual stats extracted: {list(actual_stats.keys())}")
            
            actual_trend = stats['trend_analysis']['birth_rate']['direction']
            print(f"[DEBUG] Actual trend: {actual_trend}")
        except KeyError as e:
            print(f"[ERROR] KeyError while extracting stats: {e}")
            print(f"[ERROR] Available keys in stats: {list(stats.keys() if 'stats' in locals() else 'stats not defined')}")
            raise HTTPException(
                status_code=400,
                detail=f"Missing statistic in source_statistics: {str(e)}. Available keys: {list(stats.keys() if 'stats' in locals() else source_statistics.keys())}"
            )
        
        # VERIFY STATISTICS
        try:
            verification = detector.verify_ai_statistics(ai_report, actual_stats, tolerance_percent=5.0)
        except Exception as e:
            print(f"[ERROR] verify_ai_statistics failed: {type(e).__name__}: {e}")
            verification = {
                "verified": [],
                "suspicious": [],
                "hallucinations": [],
                "accuracy_score": 0,
                "total_stats": 0,
                "correct_stats": 0,
                "suspicious_stats": 0,
                "hallucinated_stats": 0,
                "error": f"L·ªói validation: {str(e)}"
            }
        
        # CHECK TREND ACCURACY
        try:
            trend_check = detector.check_trend_accuracy(ai_report, actual_trend, country_name)
        except Exception as e:
            print(f"[ERROR] check_trend_accuracy failed: {type(e).__name__}: {e}")
            trend_check = {
                "correct": False,
                "ai_claimed": "unknown",
                "actual": actual_trend,
                "evidence": [],
                "verdict": f"L·ªói ki·ªÉm tra xu h∆∞·ªõng: {str(e)}",
                "severity": "ERROR"
            }
        
        # DETECT CONTRADICTIONS
        try:
            contradictions = detector.detect_contradictions(ai_report)
        except Exception as e:
            print(f"[ERROR] detect_contradictions failed: {type(e).__name__}: {e}")
            contradictions = []
        
        # GENERATE FULL REPORT
        try:
            validation_report = detector.generate_validation_report(
                verification, trend_check, contradictions
            )
        except Exception as e:
            print(f"[ERROR] generate_validation_report failed: {type(e).__name__}: {e}")
            raise HTTPException(status_code=500, detail=f"L·ªói t·∫°o b√°o c√°o validation: {str(e)}")
        
        return validation_report
        
    except HTTPException:
        raise
    except Exception as e:
        import traceback
        print(f"[ERROR] Validation endpoint failed:")
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"L·ªói validation: {str(e)}")
